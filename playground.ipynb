{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# old but gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gt_hw = (1520, 2704)\n",
    "# video_hw = (574, 1024)\n",
    "# warnings.warn(\"hardcoding!!!!!!\")\n",
    "# gt_bboxes = scale_gt_bbox(gt_camera, gt_hw, video_hw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA_VISIBLE_DEVICES=0 python3 eval.py --input_folder /ssd/r.musaev/deepsort/data/mvmhat_1 --mode retinanet_resnet50_fpn_v2 --embedder torchreid  --global_reid_model_wts osnet_ibn_x1_0_msmt17_combineall_256x128_amsgrad_ep150_stp60_lr0.0015_b64_fb10_softmax_labelsmooth_flip_jitter --cls 1 2 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA_VISIBLE_DEVICES=1 python3 eval.py --input_folder /ssd/r.musaev/deepsort/data/mvmhat_1 --model fasterrcnn_resnet50_fpn_v2 --embedder mobilenet --global_reid_model_wts osnet_ibn_x1_0_msmt17_combineall_256x128_amsgrad_ep150_stp60_lr0.0015_b64_fb10_softmax_labelsmooth_flip_jitter; CUDA_VISIBLE_DEVICES=1 python3 eval.py --input_folder /ssd/r.musaev/deepsort/data/mvmhat_1 --model fasterrcnn_resnet50_fpn_v2 --embedder clip_RN50x4; CUDA_VISIBLE_DEVICES=1 python3 eval.py --input_folder /ssd/r.musaev/deepsort/data/mvmhat_1 --model fasterrcnn_resnet50_fpn_v2 --embedder clip_RN50x16; CUDA_VISIBLE_DEVICES=1 python3 eval.py --input_folder /ssd/r.musaev/deepsort/data/mvmhat_1 --model fasterrcnn_resnet50_fpn_v2 --embedder clip_ViT-B/32; CUDA_VISIBLE_DEVICES=1 python3 eval.py --input_folder /ssd/r.musaev/deepsort/data/mvmhat_1 --model fasterrcnn_resnet50_fpn_v2 --embedder clip_ViT-B/16;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# detectors grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA_VISIBLE_DEVICES=1 python3 eval.py --input_folder /ssd/r.musaev/deepsort/data/mvmhat_1 --model fasterrcnn_resnet50_fpn --embedder mobilenet --global_reid_model_wts osnet_ibn_x1_0_msmt17_combineall_256x128_amsgrad_ep150_stp60_lr0.0015_b64_fb10_softmax_labelsmooth_flip_jitter; CUDA_VISIBLE_DEVICES=1 python3 eval.py --input_folder /ssd/r.musaev/deepsort/data/mvmhat_1 --model fasterrcnn_mobilenet_v3_large_fpn --embedder mobilenet --global_reid_model_wts osnet_ibn_x1_0_msmt17_combineall_256x128_amsgrad_ep150_stp60_lr0.0015_b64_fb10_softmax_labelsmooth_flip_jitter; CUDA_VISIBLE_DEVICES=1 python3 eval.py --input_folder /ssd/r.musaev/deepsort/data/mvmhat_1 --model fasterrcnn_mobilenet_v3_large_320_fpn --embedder mobilenet --global_reid_model_wts osnet_ibn_x1_0_msmt17_combineall_256x128_amsgrad_ep150_stp60_lr0.0015_b64_fb10_softmax_labelsmooth_flip_jitter; CUDA_VISIBLE_DEVICES=1 python3 eval.py --input_folder /ssd/r.musaev/deepsort/data/mvmhat_1 --model fcos_resnet50_fpn --embedder mobilenet --global_reid_model_wts osnet_ibn_x1_0_msmt17_combineall_256x128_amsgrad_ep150_stp60_lr0.0015_b64_fb10_softmax_labelsmooth_flip_jitter; CUDA_VISIBLE_DEVICES=1 python3 eval.py --input_folder /ssd/r.musaev/deepsort/data/mvmhat_1 --model ssd300_vgg16 --embedder mobilenet --global_reid_model_wts osnet_ibn_x1_0_msmt17_combineall_256x128_amsgrad_ep150_stp60_lr0.0015_b64_fb10_softmax_labelsmooth_flip_jitter; CUDA_VISIBLE_DEVICES=1 python3 eval.py --input_folder /ssd/r.musaev/deepsort/data/mvmhat_1 --model ssdlite320_mobilenet_v3_large --embedder mobilenet --global_reid_model_wts osnet_ibn_x1_0_msmt17_combineall_256x128_amsgrad_ep150_stp60_lr0.0015_b64_fb10_softmax_labelsmooth_flip_jitter; CUDA_VISIBLE_DEVICES=1 python3 eval.py --input_folder /ssd/r.musaev/deepsort/data/mvmhat_1 --model retinanet_resnet50_fpn --embedder mobilenet --global_reid_model_wts osnet_ibn_x1_0_msmt17_combineall_256x128_amsgrad_ep150_stp60_lr0.0015_b64_fb10_softmax_labelsmooth_flip_jitter; CUDA_VISIBLE_DEVICES=1 python3 eval.py --input_folder /ssd/r.musaev/deepsort/data/mvmhat_1 --model retinanet_resnet50_fpn_v2 --embedder mobilenet --global_reid_model_wts osnet_ibn_x1_0_msmt17_combineall_256x128_amsgrad_ep150_stp60_lr0.0015_b64_fb10_softmax_labelsmooth_flip_jitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA_VISIBLE_DEVICES=1 python3 eval.py --input_folder /ssd/r.musaev/deepsort/data/mvmhat_1 --model fasterrcnn_resnet50_fpn --embedder mobilenet --global_reid_model_wts osnet_ibn_x1_0_msmt17_combineall_256x128_amsgrad_ep150_stp60_lr0.0015_b64_fb10_softmax_labelsmooth_flip_jitter ; CUDA_VISIBLE_DEVICES=1 python3 eval.py --input_folder /ssd/r.musaev/deepsort/data/mvmhat_1 --model fasterrcnn_resnet50_fpn --embedder torchreid --global_reid_model_wts osnet_ibn_x1_0_msmt17_combineall_256x128_amsgrad_ep150_stp60_lr0.0015_b64_fb10_softmax_labelsmooth_flip_jitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA_VISIBLE_DEVICES=1 python3 eval.py --input_folder /ssd/r.musaev/deepsort/data/mvmhat_1 --model fasterrcnn_mobilenet_v3_large_fpn --embedder mobilenet --global_reid_model_wts osnet_ibn_x1_0_imagenet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA_VISIBLE_DEVICES=1 python3 eval.py --input_folder /ssd/r.musaev/deepsort/input/AIC22_Track1_MTMC_Tracking  --mode fasterrcnn_resnet50_fpn_v2  --embedder torchreid  --global_reid_model_wts osnet_ibn_x1_0_msmt17_combineall_256x128_amsgrad_ep150_stp60_lr0.0015_b64_fb10_softmax_labelsmooth_flip_jitter --cls 2 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import shutil\n",
    "for src in sorted(glob.glob('/ssd/r.musaev/deepsort/data/AIC22_Track1_MTMC_Tracking/validation/S02/**/*.avi')):\n",
    "    dst = '/ssd/r.musaev/deepsort/input/AIC22_Track1_MTMC_Tracking/S02'\n",
    "    dst += src.split('S02/')[1].replace('/', '_').replace('avi','mp4')\n",
    "    dst = dst.replace('_vdo', '')\n",
    "\n",
    "    shutil.copyfile(src, dst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import shutil\n",
    "for src in sorted(glob.glob('/ssd/r.musaev/deepsort/data/AIC22_Track1_MTMC_Tracking/validation/S02/*/gt/gt.txt')):\n",
    "    print(src)\n",
    "    dst = '/ssd/r.musaev/deepsort/input/AIC22_Track1_MTMC_Tracking/S02'\n",
    "    dst += src.split('S02/')[1].replace('/', '_').replace('avi','mp4')\n",
    "    dst = dst.replace('mp4', 'txt')\n",
    "    dst = dst.replace('_gt_gt','')\n",
    "    shutil.copyfile(src, dst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(vector):\n",
    "    return vector / np.linalg.norm(vector)\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import ast\n",
    "\n",
    "gt_file = '/ssd/r.musaev/deepsort/outputs/52/S02c007_retinanet_resnet50_fpn_v2_torchreid_osnet_ibn_x1_0_imagenet.txt'\n",
    "df = pd.read_csv(gt_file, names=[\n",
    "                            'fr_num', 'id', 'bbleft', 'bbtop',\n",
    "                            'bbox_width', 'bbox_height', 'det_score',\n",
    "                            'class', 'visibility', 'stuff', 'desc_reid'], index_col=False)\n",
    "                        \n",
    "df.desc_reid = df.desc_reid.apply(lambda x: np.array(ast.literal_eval(x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import motmetrics as mm\n",
    "\n",
    "def evaluate_tracker(preds, gt):\n",
    "\n",
    "    # Create MOTAccumulator object  \n",
    "    acc = mm.MOTAccumulator() \n",
    "\n",
    "    # Update with ground truth and predictions\n",
    "    for frame in range(1, len(gt) + 1):\n",
    "        gt_boxes = [[b[2], b[3], b[4], b[5]] for b in gt[gt.fr_num == frame].values]\n",
    "        hp_boxes = [[b[2], b[3], b[4], b[5]] for b in preds[preds.fr_num == frame].values]\n",
    "        print(gt_boxes)\n",
    "        print(hp_boxes)\n",
    "        \n",
    "        if gt_boxes and hp_boxes:\n",
    "            dists = mm.distances.iou_matrix(gt_boxes, hp_boxes, max_iou=0.5)\n",
    "        \n",
    "        else:\n",
    "            dists = np.zeros((0,0))\n",
    "\n",
    "        print(type(gt_boxes))\n",
    "\n",
    "        acc.update(\n",
    "            gt_boxes,  \n",
    "            hp_boxes, \n",
    "            dists,\n",
    "            frameid=frame)\n",
    "        \n",
    "        print(acc.events) \n",
    "            \n",
    "    # Get summary metrics  \n",
    "    mh = mm.metrics.create()\n",
    "    summary = mh.compute(acc, metrics=['num_frames', 'mota', 'motp'], name='acc')\n",
    "    \n",
    "    return summary  \n",
    "\n",
    "# Usage\n",
    "summary = evaluate_tracker(df, df)\n",
    "print(f\"MOTA: {summary['mota']}, MOTP: {summary['motp']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "VIDEO_PATH = '/ssd/r.musaev/deepsort/data/mvmhat_1/mvmhat_1_1.mp4'\n",
    "gt = pd.read_csv(VIDEO_PATH.replace('mp4', 'txt'), names=[\n",
    "    'fr_num', 'id', 'bbleft', 'bbtop',\n",
    "    'bbox_width', 'bbox_height', 'det_score',\n",
    "    'class', 'visibility', 'stuff',],\n",
    "                    index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def scale_gt_bbox(gt_bboxes, original_hw, target_hw):\n",
    "    \"\"\"\"applies scaling of gt-bboxes\"\"\"\n",
    "    \n",
    "    gt_bboxes.bbleft = gt_bboxes.bbleft.apply(lambda x: int(x * target_hw[1]/original_hw[1]))\n",
    "    gt_bboxes.bbtop = gt_bboxes.bbtop.apply(lambda x: int(x * target_hw[0]/original_hw[0]))\n",
    "    gt_bboxes.bbox_width = gt_bboxes.bbox_width.apply(lambda x: int(x * target_hw[1]/original_hw[1]))\n",
    "    gt_bboxes.bbox_height = gt_bboxes.bbox_height.apply(lambda x: int(x * target_hw[0]/original_hw[0]))\n",
    "    \n",
    "    return gt_bboxes\n",
    "\n",
    "VIDEO_PATH = '/ssd/r.musaev/deepsort/data/mvmhat_1/mvmhat_1_1.mp4'\n",
    "gt = pd.read_csv(VIDEO_PATH.replace('mp4', 'txt'), names=[\n",
    "    'fr_num', 'id', 'bbleft', 'bbtop',\n",
    "    'bbox_width', 'bbox_height', 'det_score',\n",
    "    'class', 'visibility', 'stuff',],\n",
    "                    index_col=False)\n",
    "\n",
    "original_hw = (1520, 2704)\n",
    "target_hw = (574, 1024)\n",
    "gt = scale_gt_bbox(gt, original_hw, target_hw)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bboxes = gt[gt.fr_num == 234].iloc[:, 2:6].values\n",
    "ids = gt[gt.fr_num == 234].iloc[:, 1].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nuscenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bcubed_eval_bcu(hyp_obj_pairs):\n",
    "    \"\"\"\n",
    "    Evaluate clustering using B-cubed metrics: precision, recall, and F1-score.\n",
    "\n",
    "    Params:\n",
    "        hyp_obj_pairs (list): List of tuples where:\n",
    "            (i_pred_cluster, j_gt_label) - correct assignment\n",
    "            (i_pred_cluster, -1) - false positive\n",
    "            (-1, j_gt_label) - false negative\n",
    "\n",
    "    Returns:\n",
    "        tuple: (precision, recall, fscore)\n",
    "    \"\"\"\n",
    "    # Initialize dictionaries to store counts\n",
    "    cluster_counts = {}\n",
    "    label_counts = {}\n",
    "    intersection_counts = {}\n",
    "\n",
    "    # Count assignments and occurrences\n",
    "    for cluster, label in hyp_obj_pairs:\n",
    "        if cluster != -1:\n",
    "            cluster_counts[cluster] = cluster_counts.get(cluster, 0) + 1\n",
    "        if label != -1:\n",
    "            label_counts[label] = label_counts.get(label, 0) + 1\n",
    "        if cluster != -1 and label != -1:\n",
    "            intersection_counts[(cluster, label)] = intersection_counts.get((cluster, label), 0) + 1\n",
    "\n",
    "    print(cluster_counts)\n",
    "    print(label_counts)\n",
    "    # Calculate precision and recall for each cluster\n",
    "    precisions = {}\n",
    "    recalls = {}\n",
    "    for cluster, label in hyp_obj_pairs:\n",
    "        if cluster == -1 or label == -1:\n",
    "            continue\n",
    "        tp = intersection_counts.get((cluster, label), 0)\n",
    "        precision = tp / cluster_counts[cluster]\n",
    "        recall = tp / label_counts[label]\n",
    "        precisions[cluster] = precisions.get(cluster, 0) + precision\n",
    "        recalls[label] = recalls.get(label, 0) + recall\n",
    "\n",
    "    # Calculate overall precision and recall\n",
    "    overall_precision = sum(precisions.values()) / len(cluster_counts)\n",
    "    overall_recall = sum(recalls.values()) / len(label_counts)\n",
    "\n",
    "    # Calculate F1-score\n",
    "    fscore = 2 * (overall_precision * overall_recall) / (overall_precision + overall_recall) if (overall_precision + overall_recall) > 0 else 0\n",
    "\n",
    "    return overall_precision, overall_recall, fscore\n",
    "\n",
    "# Example usage\n",
    "hyp_obj_pairs = [\n",
    "    (1, 1), (1, 1), (1, 2), (2, 1), (3, -1), (-1, 2), (-1, 3)\n",
    "]\n",
    "\n",
    "precision, recall, fscore = bcubed_eval_bcu(hyp_obj_pairs)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F-score:\", fscore)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import bcubed\n",
    "\n",
    "# def bcubed_eval(hyp_obj_pairs):\n",
    "#     \"\"\"\n",
    "#     Evaluate clustering using B-cubed metrics: precision and recall.\n",
    "\n",
    "#     Params:\n",
    "#         hyp_obj_pairs (list): List of tuples where:\n",
    "#             (i_pred_cluster, j_gt_label) - correct assignment\n",
    "#             (i_pred_cluster, -1) - false positive\n",
    "#             (-1, j_gt_label) - false negative\n",
    "\n",
    "#     Returns:\n",
    "#         tuple: (mean_precision, mean_recall)\n",
    "#     \"\"\"\n",
    "#     # Initialize dictionaries for predicted clusters and ground truth labels\n",
    "#     pred_clusters = {}\n",
    "#     gt_labels = {}\n",
    "\n",
    "#     # Populate dictionaries from the input list\n",
    "#     for cluster, label in hyp_obj_pairs:\n",
    "#         if cluster != -1:\n",
    "#             pred_clusters.setdefault(cluster, set()).add(label)\n",
    "#         if label != -1:\n",
    "#             gt_labels.setdefault(label, set()).add(cluster)\n",
    "\n",
    "#     # Calculate precision and recall using bcubed library\n",
    "#     precision = bcubed.precision(pred_clusters, gt_labels)\n",
    "#     recall = bcubed.recall(pred_clusters, gt_labels)\n",
    "\n",
    "#     return precision, recall\n",
    "\n",
    "# # Example usage\n",
    "# hyp_obj_pairs = [\n",
    "#     (1, \"A\"), (1, \"B\"), (2, \"A\"), (3, -1), (-1, \"B\"), (-1, \"C\")\n",
    "# ]\n",
    "\n",
    "# precision, recall = bcubed_eval(hyp_obj_pairs)\n",
    "# print(\"Precision:\", precision)\n",
    "# print(\"Recall:\", recall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.hub.load('facebookresearch/detr', 'detr_resnet50', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "CUT_FRAMES = 5000\n",
    "\n",
    "# Function to read the JSON file\n",
    "def read_json_file(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "# Function to group frames by camera\n",
    "def group_frames_by_camera(frames):\n",
    "    camera_groups = defaultdict(list)\n",
    "    for frame in frames:\n",
    "        camera_name = frame['filename'].split('/')[-2]\n",
    "        camera_groups[camera_name].append(frame)\n",
    "    return camera_groups\n",
    "\n",
    "# Function to sort frames by timestamp\n",
    "def sort_frames_by_timestamp(frames):\n",
    "    return sorted(frames, key=lambda x: x['timestamp'])\n",
    "\n",
    "# Function to join frames into a video\n",
    "def join_frames_into_video(frames, output_video_path):\n",
    "    filepath = os.path.join('/ssd/r.musaev/deepsort/data/nuimages/', frames[0]['filename'])\n",
    "    frame = cv2.imread(filepath)\n",
    "    height, width, _ = frame.shape\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    \n",
    "    for frame_info in frames[:CUT_FRAMES]:\n",
    "        filepath = os.path.join('/ssd/r.musaev/deepsort/data/nuimages/', frame_info['filename'])\n",
    "\n",
    "        if not os.path.isfile(filepath):\n",
    "            frame = np.zeros_like(frame)\n",
    "        else:\n",
    "            frame = cv2.imread(filepath)\n",
    "            height, width, _ = frame.shape\n",
    "            out = cv2.VideoWriter(output_video_path, fourcc, 2, (width, height))    \n",
    "    \n",
    "        frame = cv2.imread(filepath)\n",
    "        out.write(frame)\n",
    "    \n",
    "    out.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@155.258] global loadsave.cpp:244 findDecoder imread_('/ssd/r.musaev/deepsort/data/nuimages/samples/CAM_BACK_LEFT/n003-2018-01-02-14-02-53+0800__CAM_BACK_LEFT__1514873006282843.jpg'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@155.948] global loadsave.cpp:244 findDecoder imread_('/ssd/r.musaev/deepsort/data/nuimages/samples/CAM_BACK_LEFT/n003-2018-01-02-14-02-53+0800__CAM_BACK_LEFT__1514873011782977.jpg'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@156.910] global loadsave.cpp:244 findDecoder imread_('/ssd/r.musaev/deepsort/data/nuimages/samples/CAM_BACK_LEFT/n003-2018-01-02-14-02-53+0800__CAM_BACK_LEFT__1514873016458426.jpg'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@157.970] global loadsave.cpp:244 findDecoder imread_('/ssd/r.musaev/deepsort/data/nuimages/samples/CAM_BACK_LEFT/n003-2018-01-02-14-02-53+0800__CAM_BACK_LEFT__1514873026033537.jpg'): can't open/read file: check file path/integrity\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Join frames into a video\u001b[39;00m\n\u001b[1;32m     13\u001b[0m output_video_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmini_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcamera_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_video.mp4\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 14\u001b[0m \u001b[43mjoin_frames_into_video\u001b[49m\u001b[43m(\u001b[49m\u001b[43msorted_frames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_video_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVideo saved: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_video_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36mjoin_frames_into_video\u001b[0;34m(frames, output_video_path)\u001b[0m\n\u001b[1;32m     38\u001b[0m     frame \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros_like(frame)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 40\u001b[0m     frame \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m     height, width, _ \u001b[38;5;241m=\u001b[39m frame\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m     42\u001b[0m     out \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mVideoWriter(output_video_path, fourcc, \u001b[38;5;241m2\u001b[39m, (width, height))    \n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Read the JSON file\n",
    "data = read_json_file('/ssd/r.musaev/deepsort/data/nuimages/v1.0-val/sample_data.json')\n",
    "\n",
    "# # Group frames by camera\n",
    "camera_groups = group_frames_by_camera(data)\n",
    "\n",
    "# # Process each camera group\n",
    "for camera_name, frames in camera_groups.items():\n",
    "    # Sort frames by timestamp\n",
    "    sorted_frames = sort_frames_by_timestamp(frames)\n",
    "    \n",
    "    # Join frames into a video\n",
    "    output_video_path = f'mini_{camera_name}_video.mp4'\n",
    "    join_frames_into_video(sorted_frames, output_video_path)\n",
    "    print(f'Video saved: {output_video_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read the JSON file\n",
    "# data = read_json_file('/ssd/r.musaev/deepsort/data/nuimages/v1.0-mini/sample_data.json')\n",
    "\n",
    "# # # Group frames by camera\n",
    "# camera_groups = group_frames_by_camera(data)\n",
    "\n",
    "# # # Process each camera group\n",
    "# for camera_name, frames in camera_groups.items():\n",
    "#     # Sort frames by timestamp\n",
    "#     sorted_frames = sort_frames_by_timestamp(frames)\n",
    "    \n",
    "#     # Join frames into a video\n",
    "#     output_video_path = f'mini_{camera_name}_video.mp4'\n",
    "#     join_frames_into_video(sorted_frames, output_video_path)\n",
    "#     print(f'Video saved: {output_video_path}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Camera 0 Metrics:</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IDF1    IDP    IDR   Rcll   Prcn GT MT ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>full  72.0%  73.5%  70.7%  95.5%  99.4%  8  8 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>part 100.0% 100.0% 100.0% 100.0% 100.0%  7  7 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Camera 1 Metrics:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IDF1    IDP   IDR  Rcll   Prcn GT MT PT ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>full 59.5%  64.8% 55.0% 84.5%  99.6%  8  6  1 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>part 83.3% 100.0% 71.4% 71.4% 100.0%  7  5  0 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Camera 2 Metrics:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>IDF1    IDP   IDR  Rcll   Prcn GT MT PT ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>full 57.0%  59.1% 55.1% 92.7%  99.5%  7  7  0 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>part 90.9% 100.0% 83.3% 83.3% 100.0%  6  5  0 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Camera 3 Metrics:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>IDF1    IDP    IDR   Rcll   Prcn GT MT ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>full  64.7%  68.1%  61.7%  90.3%  99.7%  8  7 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>part 100.0% 100.0% 100.0% 100.0% 100.0%  5  5 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Camera 0 Metrics:\n",
       "0          IDF1    IDP    IDR   Rcll   Prcn GT MT ...\n",
       "1   full  72.0%  73.5%  70.7%  95.5%  99.4%  8  8 ...\n",
       "2   part 100.0% 100.0% 100.0% 100.0% 100.0%  7  7 ...\n",
       "3                                   Camera 1 Metrics:\n",
       "4         IDF1    IDP   IDR  Rcll   Prcn GT MT PT ...\n",
       "5   full 59.5%  64.8% 55.0% 84.5%  99.6%  8  6  1 ...\n",
       "6   part 83.3% 100.0% 71.4% 71.4% 100.0%  7  5  0 ...\n",
       "7                                   Camera 2 Metrics:\n",
       "8         IDF1    IDP   IDR  Rcll   Prcn GT MT PT ...\n",
       "9   full 57.0%  59.1% 55.1% 92.7%  99.5%  7  7  0 ...\n",
       "10  part 90.9% 100.0% 83.3% 83.3% 100.0%  6  5  0 ...\n",
       "11                                  Camera 3 Metrics:\n",
       "12         IDF1    IDP    IDR   Rcll   Prcn GT MT ...\n",
       "13  full  64.7%  68.1%  61.7%  90.3%  99.7%  8  7 ...\n",
       "14  part 100.0% 100.0% 100.0% 100.0% 100.0%  5  5 ..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.read_csv('/ssd/r.musaev/deepsort/outputs/54/metrics_mot.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "178553"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "camera_name = 'CAM_FRONT_LEFT'\n",
    "frame_pathes = sorted(glob.glob(f'/ssd/r.musaev/deepsort/data/nuimages/sweeps/{camera_name}/*'), key=lambda x: x.split('_')[-1])\n",
    "\n",
    "filepath = frame_pathes[0]\n",
    "frame = cv2.imread(filepath)\n",
    "height, width, _ = frame.shape\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "output_video_path = f'mini_{camera_name}_video.mp4'\n",
    "out = cv2.VideoWriter(output_video_path, fourcc, 2.0, (width, height))\n",
    "\n",
    "for frame_path in frame_pathes[:1000]:\n",
    "    frame = cv2.imread(frame_path)\n",
    "    out.write(frame)\n",
    "\n",
    "out.release()\n",
    "output_video_path\n",
    "\n",
    "len(frame_pathes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# import os\n",
    "# from collections import defaultdict\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "# from pycocotools import mask as mask_utils\n",
    "\n",
    "# # Function to read the JSON file\n",
    "# def read_json_file(file_path):\n",
    "#     with open(file_path, 'r') as f:\n",
    "#         data = json.load(f)\n",
    "#     return data\n",
    "\n",
    "# # Function to group frames by camera\n",
    "# def group_frames_by_camera(frames):\n",
    "#     camera_groups = defaultdict(list)\n",
    "#     for frame in frames:\n",
    "#         camera_name = frame['filename'].split('/')[-2]\n",
    "#         camera_groups[camera_name].append(frame)\n",
    "#     return camera_groups\n",
    "\n",
    "# # Function to sort frames by timestamp\n",
    "# def sort_frames_by_timestamp(frames):\n",
    "#     return sorted(frames, key=lambda x: x['timestamp'])\n",
    "\n",
    "# # filter out class\n",
    "# def get_category_tokens(category_data, target_category):\n",
    "#     tokens = []    \n",
    "#     for category in category_data:\n",
    "#         if target_category in category['name']:\n",
    "#             tokens.append(category['token'])\n",
    "#     return tokens\n",
    "\n",
    "# # Function to join frames into a video with annotations\n",
    "# def join_frames_into_annotated_video(frames, annotations, category_meta, output_video_path):\n",
    "#     filepath = os.path.join('/ssd/r.musaev/deepsort/data/nuimages/', frames[0]['filename'])\n",
    "\n",
    "#     frame = cv2.imread(filepath)\n",
    "#     height, width, _ = frame.shape\n",
    "#     fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "#     out = cv2.VideoWriter(output_video_path, fourcc, 30.0, (width, height))\n",
    "\n",
    "#     # define category:\n",
    "#     category_tokens = get_category_tokens(category_meta, 'vehicle')\n",
    "    \n",
    "#     for frame_info in frames:\n",
    "#         filepath = os.path.join('/ssd/r.musaev/deepsort/data/nuimages/', frame_info['filename'])\n",
    "#         frame = cv2.imread(filepath)\n",
    "        \n",
    "#         # Retrieve annotations for the current frame\n",
    "#         frame_annotations = [ann for ann in annotations if ann['sample_data_token'] == frame_info['token'] and ann['category_token'] in category_tokens]\n",
    "        \n",
    "#         # Draw bounding boxes on the frame\n",
    "#         for ann in frame_annotations:\n",
    "#             bbox = ann['bbox']\n",
    "#             cv2.rectangle(frame, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (0, 255, 0), 2)\n",
    "        \n",
    "#         out.write(frame)\n",
    "    \n",
    "#     out.release()\n",
    "\n",
    "\n",
    "# # Read the JSON files\n",
    "# frame_data = read_json_file('/ssd/r.musaev/deepsort/data/nuimages/v1.0-mini/sample_data.json')\n",
    "# annotation_data = read_json_file('/ssd/r.musaev/deepsort/data/nuimages/v1.0-mini/object_ann.json')\n",
    "# category_data = read_json_file('/ssd/r.musaev/deepsort/data/nuimages/v1.0-mini/category.json')\n",
    "\n",
    "# # Group frames by camera\n",
    "# camera_groups = group_frames_by_camera(frame_data)\n",
    "\n",
    "# # Process each camera group\n",
    "# for camera_name, frames in camera_groups.items():\n",
    "#     # Sort frames by timestamp\n",
    "#     sorted_frames = sort_frames_by_timestamp(frames)\n",
    "    \n",
    "#     # Join frames into an annotated video\n",
    "#     output_video_path = f'{camera_name}_annotated_video.mp4'\n",
    "#     join_frames_into_annotated_video(sorted_frames, annotation_data, category_data, output_video_path)\n",
    "#     print(f'Annotated video saved: {output_video_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "TOTAL_FRAMES = 1000\n",
    "\n",
    "def save_annotations_in_mot_format(frames, annotations, category_meta, output_mot_file):\n",
    "    with open(output_mot_file, 'w') as f:\n",
    "        # Write MOT header\n",
    "        # f.write(\"frame_num, object_id, x_min, y_min, width, height\\n\")\n",
    "        \n",
    "        # define category:\n",
    "        category_tokens = get_category_tokens(category_meta, 'vehicle')\n",
    "        \n",
    "        for frame_info in frames[:TOTAL_FRAMES]:\n",
    "            # Retrieve frame number\n",
    "            frame_num = frame_info['timestamp']  # Modify this according to your frame numbering\n",
    "            \n",
    "            # Retrieve annotations for the current frame and filter only vehicles\n",
    "            frame_annotations = [ann for ann in annotations if ann['sample_data_token'] == frame_info['token'] and ann['category_token'] in category_tokens]\n",
    "            \n",
    "            # Write annotations to the MOT file\n",
    "            for ann in frame_annotations:\n",
    "                bbox = ann['bbox']\n",
    "                object_id = ann['token']  # Use annotation token as object ID\n",
    "                x_min, y_min, width, height = bbox[0], bbox[1], bbox[2] - bbox[0], bbox[3] - bbox[1]\n",
    "                line = f\"{frame_num},{object_id},{x_min},{y_min},{width},{height}\\n\"\n",
    "                f.write(line)\n",
    "\n",
    "# Modify the function to include saving annotations in MOT format\n",
    "def join_frames_save_annotation(frames, annotations, category_meta, output_video_path, draw_boxes=False):\n",
    "    filepath = os.path.join('/ssd/r.musaev/deepsort/data/nuimages/', frames[0]['filename'])\n",
    "    frame = cv2.imread(filepath)\n",
    "    height, width, _ = frame.shape\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_video_path, fourcc, fps=20, frameSize=(width, height))\n",
    "\n",
    "    # Define category:\n",
    "    category_tokens = get_category_tokens(category_meta, 'vehicle')\n",
    "    \n",
    "    # Specify the output MOT file path\n",
    "    output_mot_file = output_video_path.replace('.mp4', '.txt')\n",
    "\n",
    "    for frame_info in tqdm(frames[:TOTAL_FRAMES]):\n",
    "        filepath = os.path.join('/ssd/r.musaev/deepsort/data/nuimages/', frame_info['filename'])\n",
    "        if not os.path.isfile(filepath):\n",
    "            continue\n",
    "        frame = cv2.imread(filepath)\n",
    "        \n",
    "        if draw_boxes:\n",
    "            # Retrieve annotations for the current frame\n",
    "            frame_annotations = [ann for ann in annotations if ann['sample_data_token'] == frame_info['token'] and ann['category_token'] in category_tokens]\n",
    "            \n",
    "            # Draw bounding boxes on the frame\n",
    "            for ann in frame_annotations:\n",
    "                bbox = ann['bbox']\n",
    "                cv2.rectangle(frame, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (0, 255, 0), 2)\n",
    "            \n",
    "        out.write(frame)\n",
    "    \n",
    "    # Save annotations in MOT format\n",
    "    save_annotations_in_mot_format(frames, annotations, category_meta, output_mot_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frame_annotations = [ann for ann in annotation_data if ann['sample_data_token'] == frame_data[0]['token']]\n",
    "# frame_annotations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted_frames[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the JSON files\n",
    "frame_data = read_json_file('/ssd/r.musaev/deepsort/data/nuimages/v1.0-val/sample_data.json')\n",
    "annotation_data = read_json_file('/ssd/r.musaev/deepsort/data/nuimages/v1.0-val/object_ann.json')\n",
    "category_data = read_json_file('/ssd/r.musaev/deepsort/data/nuimages/v1.0-val/category.json')\n",
    "\n",
    "# Group frames by camera\n",
    "camera_groups = group_frames_by_camera(frame_data)\n",
    "\n",
    "# Process each camera group\n",
    "for camera_name, frames in camera_groups.items():\n",
    "    # Sort frames by timestamp\n",
    "    sorted_frames = sort_frames_by_timestamp(frames)\n",
    "    \n",
    "    # Join frames into an annotated video\n",
    "    output_video_path = f'/ssd/r.musaev/deepsort/input/nuimages/v1.0-test/{camera_name}.mp4'\n",
    "    join_frames_save_annotation(sorted_frames, annotation_data, category_data, output_video_path)\n",
    "    print(f'Annotated video saved: {output_video_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import ast\n",
    "\n",
    "gt_file = '/ssd/r.musaev/deepsort/input/nuimages/v1.0-test/CAM_BACK.txt'\n",
    "df = pd.read_csv(gt_file, names=[\n",
    "                            'fr_num', 'id', 'bbleft', 'bbtop',\n",
    "                            'bbox_width', 'bbox_height', 'det_score',\n",
    "                            'class', 'visibility', 'stuff', 'desc_reid'], index_col=False)\n",
    "df.fr_num.unique()                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import ast\n",
    "\n",
    "gt_file = '/ssd/r.musaev/deepsort/input/nuimages/v1.0-test/CAM_BACK_LEFT.txt'\n",
    "df = pd.read_csv(gt_file, names=[\n",
    "                            'fr_num', 'id', 'bbleft', 'bbtop',\n",
    "                            'bbox_width', 'bbox_height', 'det_score',\n",
    "                            'class', 'visibility', 'stuff', 'desc_reid'], index_col=False)\n",
    "df.fr_num.unique()                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import ast\n",
    "\n",
    "gt_file = '/ssd/r.musaev/deepsort/outputs/57/video4_retinanet_resnet50_fpn_v2_torchreid_osnet_ibn_x1_0_msmt17_combineall_256x128_amsgrad_ep150_stp60_lr0.0015_b64_fb10_softmax_labelsmooth_flip_jitter.txt'\n",
    "df = pd.read_csv(gt_file, names=[\n",
    "                            'fr_num', 'id', 'bbleft', 'bbtop',\n",
    "                            'bbox_width', 'bbox_height', 'det_score',\n",
    "                            'class', 'visibility', 'stuff', 'desc_reid'], index_col=False)\n",
    "df['desc_reid'] = df['desc_reid'].apply(lambda x: np.array(ast.literal_eval(x)))\n",
    "\n",
    "df_mcmt = pd.DataFrame(\n",
    "    columns=[\n",
    "        'fr_num', 'id', 'bbleft', 'bbtop',\n",
    "        'bbox_width', 'bbox_height', 'det_score', 'class'\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "num_camera = 0\n",
    "\n",
    "df['camera'] = num_camera\n",
    "\n",
    "tracks = [f\"{x}_c{num_camera}\" for x in df['id']]\n",
    "\n",
    "df['id'] = df['id'].apply(lambda x: f\"{x}_c{num_camera}\")\n",
    "\n",
    "df_sbst = df[['camera', 'id', 'bbleft', 'bbtop',\n",
    "                'bbox_width', 'bbox_height', 'det_score', 'class']]\n",
    "\n",
    "df_mcmt = pd.concat([df_mcmt, df_sbst])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fr_num</th>\n",
       "      <th>id</th>\n",
       "      <th>bbleft</th>\n",
       "      <th>bbtop</th>\n",
       "      <th>bbox_width</th>\n",
       "      <th>bbox_height</th>\n",
       "      <th>det_score</th>\n",
       "      <th>class</th>\n",
       "      <th>visibility</th>\n",
       "      <th>stuff</th>\n",
       "      <th>desc_reid</th>\n",
       "      <th>camera</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1_c0</td>\n",
       "      <td>862</td>\n",
       "      <td>340</td>\n",
       "      <td>133</td>\n",
       "      <td>361</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>[0.0, 3.67199731, 0.0, 0.472329348, 1.09158492...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2_c0</td>\n",
       "      <td>2108</td>\n",
       "      <td>366</td>\n",
       "      <td>158</td>\n",
       "      <td>433</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.498367459, 0.0, 0.0, 0....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3_c0</td>\n",
       "      <td>1342</td>\n",
       "      <td>369</td>\n",
       "      <td>159</td>\n",
       "      <td>441</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>[0.0, 0.28717968, 0.0, 0.10863856, 0.16550319,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4_c0</td>\n",
       "      <td>4</td>\n",
       "      <td>371</td>\n",
       "      <td>112</td>\n",
       "      <td>267</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>[0.0, 2.59539247, 0.0, 0.0, 0.292697549, 0.0, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5_c0</td>\n",
       "      <td>1834</td>\n",
       "      <td>393</td>\n",
       "      <td>64</td>\n",
       "      <td>192</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>[0.0, 0.658252358, 0.0, 0.0, 0.880500257, 0.0,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7668</th>\n",
       "      <td>1261</td>\n",
       "      <td>22_c0</td>\n",
       "      <td>133</td>\n",
       "      <td>394</td>\n",
       "      <td>91</td>\n",
       "      <td>258</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>[0.0, 2.52326155, 0.0, 0.0, 0.124475852, 0.0, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7669</th>\n",
       "      <td>1261</td>\n",
       "      <td>26_c0</td>\n",
       "      <td>1766</td>\n",
       "      <td>401</td>\n",
       "      <td>127</td>\n",
       "      <td>376</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>[0.0, 0.14387472, 0.0, 0.167395547, 0.18049204...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7670</th>\n",
       "      <td>1261</td>\n",
       "      <td>39_c0</td>\n",
       "      <td>1512</td>\n",
       "      <td>394</td>\n",
       "      <td>158</td>\n",
       "      <td>385</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>[0.0, 0.125443831, 0.0, 0.209912464, 0.0, 0.0,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7671</th>\n",
       "      <td>1261</td>\n",
       "      <td>43_c0</td>\n",
       "      <td>1905</td>\n",
       "      <td>431</td>\n",
       "      <td>68</td>\n",
       "      <td>192</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>[0.0, 0.015562619, 0.0, 0.0, 0.46701524, 0.0, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7672</th>\n",
       "      <td>1261</td>\n",
       "      <td>45_c0</td>\n",
       "      <td>964</td>\n",
       "      <td>416</td>\n",
       "      <td>56</td>\n",
       "      <td>157</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>[0.0, 2.50956035, 0.0, 0.0, 0.496526301, 0.0, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7673 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fr_num     id  bbleft  bbtop  bbox_width  bbox_height  det_score  class  \\\n",
       "0          1   1_c0     862    340         133          361         -1     -1   \n",
       "1          1   2_c0    2108    366         158          433         -1     -1   \n",
       "2          1   3_c0    1342    369         159          441         -1     -1   \n",
       "3          1   4_c0       4    371         112          267         -1     -1   \n",
       "4          1   5_c0    1834    393          64          192         -1     -1   \n",
       "...      ...    ...     ...    ...         ...          ...        ...    ...   \n",
       "7668    1261  22_c0     133    394          91          258         -1     -1   \n",
       "7669    1261  26_c0    1766    401         127          376         -1     -1   \n",
       "7670    1261  39_c0    1512    394         158          385         -1     -1   \n",
       "7671    1261  43_c0    1905    431          68          192         -1     -1   \n",
       "7672    1261  45_c0     964    416          56          157         -1     -1   \n",
       "\n",
       "      visibility  stuff                                          desc_reid  \\\n",
       "0             -1     -1  [0.0, 3.67199731, 0.0, 0.472329348, 1.09158492...   \n",
       "1             -1     -1  [0.0, 0.0, 0.0, 0.0, 0.498367459, 0.0, 0.0, 0....   \n",
       "2             -1     -1  [0.0, 0.28717968, 0.0, 0.10863856, 0.16550319,...   \n",
       "3             -1     -1  [0.0, 2.59539247, 0.0, 0.0, 0.292697549, 0.0, ...   \n",
       "4             -1     -1  [0.0, 0.658252358, 0.0, 0.0, 0.880500257, 0.0,...   \n",
       "...          ...    ...                                                ...   \n",
       "7668          -1     -1  [0.0, 2.52326155, 0.0, 0.0, 0.124475852, 0.0, ...   \n",
       "7669          -1     -1  [0.0, 0.14387472, 0.0, 0.167395547, 0.18049204...   \n",
       "7670          -1     -1  [0.0, 0.125443831, 0.0, 0.209912464, 0.0, 0.0,...   \n",
       "7671          -1     -1  [0.0, 0.015562619, 0.0, 0.0, 0.46701524, 0.0, ...   \n",
       "7672          -1     -1  [0.0, 2.50956035, 0.0, 0.0, 0.496526301, 0.0, ...   \n",
       "\n",
       "      camera  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  \n",
       "...      ...  \n",
       "7668       0  \n",
       "7669       0  \n",
       "7670       0  \n",
       "7671       0  \n",
       "7672       0  \n",
       "\n",
       "[7673 rows x 12 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = [\n",
    "    (1, 2),  # True positive\n",
    "    (1, 1),  # True positive\n",
    "    (2, 1),  # True positive\n",
    "    (2, 2),  # True positive\n",
    "    (3, -1), # False positive\n",
    "    (4, -1), # False positive\n",
    "    (5, -1), # False positive\n",
    "    (-1, 3), # False negative\n",
    "    (-1, 4), # False negative\n",
    "    (-1, 5)  # False negative\n",
    "]\n",
    "\n",
    "# Initialize dictionaries to store clusters and labels\n",
    "clusters = {}\n",
    "labels = {}\n",
    "\n",
    "# Fill in clusters and labels dictionaries\n",
    "for cluster, label in sample_data:\n",
    "    if cluster != -1:\n",
    "        if cluster in clusters:\n",
    "            clusters[cluster].append(label)\n",
    "        else:\n",
    "            clusters[cluster] = [label]\n",
    "    \n",
    "    if label != -1:\n",
    "        if label in labels:\n",
    "            labels[label].append(cluster)\n",
    "        else:\n",
    "            labels[label] = [cluster]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate precision\n",
    "precision = 0.0\n",
    "total_pairs = 0\n",
    "for cluster, label_list in clusters.items():\n",
    "    for label in label_list:\n",
    "        correct = label_list.count(label)\n",
    "        total_pairs += correct\n",
    "        precision += correct / len(label_list)\n",
    "\n",
    "precision /= total_pairs\n",
    "\n",
    "# Calculate recall\n",
    "recall = 0.0\n",
    "total_pairs = 0\n",
    "for label, cluster_list in labels.items():\n",
    "    for cluster in cluster_list:\n",
    "        correct = cluster_list.count(cluster)\n",
    "        total_pairs += correct\n",
    "        recall += correct / len(cluster_list)\n",
    "\n",
    "recall /= total_pairs\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bcubed_eval(sample_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def bcubed_eval(hyp_obj_pairs):\n",
    "    \"\"\"cluster evaluation function\n",
    "    Based on https://link.springer.com/article/10.1007/s10791-008-9066-8\n",
    "\n",
    "    Params\n",
    "    ------\n",
    "    hyp_obj_pairs: list\n",
    "        list of tuples where:\n",
    "            (i_pred_cluster, j_gt_label) - correct assignment\n",
    "            (i_pred_cluster, -1) - fp\n",
    "            (-1, j_gt_label) - fn\n",
    "\n",
    "    Returns\n",
    "    ------\n",
    "    (mean_p, mean_r): tuple\n",
    "        mean (precision, recall) per threshold\n",
    "    \"\"\"\n",
    "\n",
    "    AVERAGE_PRECISION = 0.0\n",
    "    AVERAGE_RECALL = 0.0\n",
    "    AVERAGE_FP = 0.0\n",
    "    recall_items = 0\n",
    "    precision_items = 0\n",
    "    used_pairs = set()\n",
    "\n",
    "    hyp_obj_pairs = sorted(hyp_obj_pairs)\n",
    "    for pair in tqdm(hyp_obj_pairs):\n",
    "        if pair in used_pairs:\n",
    "            continue\n",
    "\n",
    "        tp = 0\n",
    "        same_cluster = 0\n",
    "        same_label = 0\n",
    "\n",
    "        if pair[0] == pair[1] == -1:\n",
    "            print('\\n\\n\\n\\n\\n')\n",
    "            print('pair[0] == pair[0] == -1')\n",
    "            print('\\n\\n\\n\\n\\n')\n",
    "\n",
    "        if pair[1] == -1:  # FP\n",
    "            AVERAGE_PRECISION += 0\n",
    "            precision_items += 1\n",
    "            AVERAGE_FP += 1\n",
    "            continue\n",
    "\n",
    "        if pair[0] == -1:  # FN\n",
    "            AVERAGE_RECALL += 0\n",
    "            recall_items += 1\n",
    "            continue\n",
    "\n",
    "        for item in hyp_obj_pairs:\n",
    "            if item[0] == pair[0]:\n",
    "                same_cluster += 1\n",
    "                if item[1] == pair[1]:\n",
    "                    tp += 1\n",
    "\n",
    "            if item[1] == pair[1]:\n",
    "                same_label += 1\n",
    "\n",
    "        p = tp / same_cluster\n",
    "        assert p <= 1\n",
    "        AVERAGE_PRECISION += p * tp\n",
    "        precision_items += tp\n",
    "\n",
    "        r = tp / same_label\n",
    "        assert r <= 1\n",
    "        AVERAGE_RECALL += r * tp\n",
    "        recall_items += tp\n",
    "        used_pairs.add(pair)\n",
    "\n",
    "    mean_p = AVERAGE_PRECISION / precision_items\n",
    "    mean_r = AVERAGE_RECALL / recall_items\n",
    "    mean_fp_rate = AVERAGE_FP / precision_items\n",
    "    print(\"mean_fp_rate\", mean_fp_rate, \"1-mean_p\", 1-mean_p, \"mean_p\", mean_p)\n",
    "    return (mean_p, mean_r, mean_fp_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# draw gt boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "\n",
    "video_path = '/ssd/r.musaev/deepsort/input/AIC22_Track1_MTMC_Tracking/S02c006.mp4'\n",
    "out_dir = '/ssd/r.musaev/deepsort/input/'\n",
    "\n",
    "# Video stream\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "frame_fps = int(cap.get(5))\n",
    "frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "save_name = video_path.split(os.path.sep)[-1].split('.')[0]\n",
    "\n",
    "# Define codec and create VideoWriter object\n",
    "out = cv2.VideoWriter(\n",
    "    f\"{out_dir}/{save_name}_annotated.mp4\",\n",
    "    cv2.VideoWriter_fourcc(*'mp4v'), frame_fps,\n",
    "    (frame_width, frame_height)\n",
    ")\n",
    "\n",
    "frame_count = 0  # To count total frames\n",
    "total_fps = 0  # To get the final frames per second\n",
    "\n",
    "gt_camera = pd.read_csv(video_path.replace('mp4', 'txt'), names=[\n",
    "    'fr_num', 'id', 'bbleft', 'bbtop',\n",
    "    'bbox_width', 'bbox_height', 'det_score',\n",
    "    'class', 'visibility', 'stuff'],\n",
    "                    index_col=False)\n",
    "\n",
    "while cap.isOpened():\n",
    "    # Read a frame\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        frame_count += 1\n",
    "\n",
    "        # Get ground truth bounding boxes for the current frame\n",
    "        gt_bboxes = gt_camera[(gt_camera['fr_num'] == frame_count)]\n",
    "        \n",
    "        # Draw ground truth bounding boxes\n",
    "        for _, bbox in gt_bboxes.iterrows():\n",
    "            left = int(bbox['bbleft'])\n",
    "            top = int(bbox['bbtop'])\n",
    "            width = int(bbox['bbox_width'])\n",
    "            height = int(bbox['bbox_height'])\n",
    "            cv2.rectangle(frame, (left, top), (left + width, top + height), (0, 255, 0), 2)\n",
    "\n",
    "        # Write the annotated frame to the output video\n",
    "        out.write(frame)\n",
    "\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "def create_video_from_images(image_folder, output_video_path, fps=30):\n",
    "    # Get the list of images in the folder\n",
    "    images = [img for img in os.listdir(image_folder) if img.endswith(\".png\")]\n",
    "    frame = cv2.imread(os.path.join(image_folder, images[0]))\n",
    "    height, width, layers = frame.shape\n",
    "\n",
    "    # Define the codec and create VideoWriter object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Be sure to use the lower case\n",
    "    video = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
    "\n",
    "    for image in images:\n",
    "        video.write(cv2.imread(os.path.join(image_folder, image)))\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    video.release()\n",
    "\n",
    "# Specify input image folder and output video path\n",
    "image_folder = '/ssd/r.musaev/deepsort/data/Wildtrack_dataset/Image_subsets/C1'\n",
    "output_video_path = '/ssd/r.musaev/deepsort/data/Wildtrack_dataset/Image_subsets/C1.mp4'\n",
    "\n",
    "# Create the video from images\n",
    "create_video_from_images(image_folder, output_video_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AIC22_Track1_MTMC_Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/ssd/r.musaev/deepsort/data/AIC22_Track1_MTMC_Tracking/eval/ground_truth_validation.txt', names=[\n",
    "    'camera', 'fr_num', 'id', 'bbleft', 'bbtop',\n",
    "    'bbox_width', 'bbox_height', 'det_score',\n",
    "    'class',], index_col=False, sep=' ')\n",
    "\n",
    "\n",
    "df = df[df.camera.apply(lambda x: x in [6, 7, 8, 9])]\n",
    "df.to_csv('/ssd/r.musaev/deepsort/data/AIC22_Track1_MTMC_Tracking/eval/ground_truth_validation_S02.txt', header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_708390/2947009353.py:7: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  df = pd.read_csv(path, names=[\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "cams = [6,7,8,9]\n",
    "for i, path in enumerate(sorted(glob.glob(\"/ssd/r.musaev/deepsort/outputs/53/*.txt\"))):\n",
    "\n",
    "\n",
    "    df = pd.read_csv(path, names=[\n",
    "    'fr_num', 'id', 'bbleft', 'bbtop',\n",
    "    'bbox_width', 'bbox_height', 'det_score',\n",
    "    'class', 'visibility', 'stuff',],\n",
    "                    index_col=False)\n",
    "    \n",
    "    df['camera'] = cams[i]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mcmt = pd.DataFrame(\n",
    "    columns=[\n",
    "        'fr_num', 'id', 'bbleft', 'bbtop',\n",
    "        'bbox_width', 'bbox_height', 'det_score', 'class'\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast \n",
    "\n",
    "num_camera = 0\n",
    "df_mcmt = pd.DataFrame(\n",
    "    columns=[\n",
    "        'fr_num', 'id', 'bbleft', 'bbtop',\n",
    "        'bbox_width', 'bbox_height', 'det_score', 'class'\n",
    "    ]\n",
    ")\n",
    "camera_hyp = '/ssd/r.musaev/deepsort/outputs/57/video1_retinanet_resnet50_fpn_v2_torchreid_osnet_ibn_x1_0_msmt17_combineall_256x128_amsgrad_ep150_stp60_lr0.0015_b64_fb10_softmax_labelsmooth_flip_jitter.txt'\n",
    "df = pd.read_csv(\n",
    "    camera_hyp,\n",
    "    names=[\n",
    "        'fr_num', 'id', 'bbleft', 'bbtop',\n",
    "        'bbox_width', 'bbox_height', 'det_score',\n",
    "        'class', 'visibility', 'stuff', 'desc_reid'\n",
    "    ],\n",
    "    index_col=False\n",
    ")\n",
    "\n",
    "df['camera'] = num_camera\n",
    "\n",
    "df['id'] = df['id'].apply(lambda x: f\"{x}_c{num_camera}\")\n",
    "\n",
    "df_sbst = df[['camera', 'id', 'bbleft', 'bbtop',\n",
    "                'bbox_width', 'bbox_height', 'det_score', 'class']]\n",
    "\n",
    "df_mcmt = pd.concat([df_mcmt, df_sbst])\n",
    "\n",
    "# Re-ID preparation: agg and normalize \n",
    "df['desc_reid'] = df['desc_reid'].apply(lambda x: np.array(ast.literal_eval(x)))\n",
    "df = df.groupby('id')['desc_reid'].agg('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "index2track = {}\n",
    "index = 0\n",
    "df = pd.read_csv(camera_hyp, names=[\n",
    "    'fr_num', 'id', 'bbleft', 'bbtop',\n",
    "    'bbox_width', 'bbox_height', 'det_score',\n",
    "    'class', 'visibility', 'stuff', 'desc_reid'],\n",
    "                    index_col=False)\n",
    "df['camera'] = num_camera\n",
    "\n",
    "tracks = list(map(lambda x: str(x) + f'_c{num_camera}', df['id']))\n",
    "tracks = dict(zip(np.arange(index, index + len(df['id'])), tracks))\n",
    "index += len(df['id'])\n",
    "\n",
    "index2track.update(tracks)\n",
    "\n",
    "df['id'] = df['id'].apply(lambda x: str(x) + f'_c{num_camera}')\n",
    "df_mcmt.update(df[['camera', 'id', 'bbleft', 'bbtop',\n",
    "                    'bbox_width', 'bbox_height', 'det_score', 'class']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks1 = list(map(lambda x: str(x) + f'_c{num_camera}', df['id']))\n",
    "tracks1 = dict(zip(np.arange(index, index + len(df['id'])), tracks1))\n",
    "\n",
    "tracks2 = [f\"{x}_c{num_camera}\" for x in df['id']]\n",
    "tracks2 = dict(zip(range(index, index + len(df['id'])), tracks2))\n",
    "\n",
    "\n",
    "\n",
    "df['desc_reid'] = df['desc_reid'].apply(lambda x: np.array(ast.literal_eval(x)))\n",
    "df = df.groupby('id')['desc_reid'].agg('mean')\n",
    "df = df.apply(lambda x: normalize(x))\n",
    "descs = np.vstack(df.values.tolist())\n",
    "\n",
    "descriptors.append(descs)\n",
    "\n",
    "tracks = list(map(lambda x: str(x) + f'_c{num}', df.keys()))\n",
    "tracks = dict(zip(np.arange(index, index + len(df.keys())), tracks))\n",
    "\n",
    "index += len(df.keys())\n",
    "index2track.update(tracks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from tqdm import tqdm\n",
    "\n",
    "def normalize(vector):\n",
    "    return vector / np.linalg.norm(vector)\n",
    "\n",
    "\n",
    "def clusterize(matrix_dist, threshold, index2track):\n",
    "    \"\"\"Run clustering.\n",
    "\n",
    "    Parameters:\n",
    "    matrix_dist (np.array): 2D matrix with distances between local tracks.\n",
    "\n",
    "    Returns:\n",
    "    clusters (list): List of sets of global indexes of tracks from clique.\n",
    "    track2cluster_num (dict): Maps global index of track to cluster index.\n",
    "    \"\"\"\n",
    "    clusters_matrix = np.where(matrix_dist < threshold, 1, 0)\n",
    "    clusters = []\n",
    "    track2cluster = {}\n",
    "\n",
    "    for track_index in range(len(clusters_matrix)):\n",
    "        nodes = np.nonzero(clusters_matrix[track_index, :])[0]\n",
    "        clusters = update_clusters_list(clusters, track_index, nodes)\n",
    "\n",
    "    for num_cluster, cluster in enumerate(clusters):\n",
    "        for track_index in cluster:\n",
    "            global_track_name = index2track[track_index]\n",
    "            track2cluster[global_track_name] = num_cluster\n",
    "\n",
    "    return track2cluster\n",
    "\n",
    "\n",
    "def update_clusters_list(clusters, track, nodes):  # TODO: OPTIMIZE clique updating\n",
    "    \"\"\"Find clique for curent edges[track,nodes]\n",
    "    Params\n",
    "    ------\n",
    "    clusters: list\n",
    "        containts list of clusters (sets)\n",
    "    track:  int\n",
    "        initial track-node\n",
    "    nodes:\n",
    "        other tracks-nodes connected with node\n",
    "\n",
    "    Returns\n",
    "    ------\n",
    "    clusters: list\n",
    "        list of global indexes of tracks of clique\n",
    "    \"\"\"\n",
    "\n",
    "    tmp_cluster = set([track, *nodes])\n",
    "    new_nodes = sorted(list(tmp_cluster))\n",
    "    for node in new_nodes:\n",
    "        for cluster_set in clusters:\n",
    "            if node in cluster_set:\n",
    "                cluster_set.update(tmp_cluster)\n",
    "                tmp_cluster = cluster_set.copy()\n",
    "                clusters.remove(cluster_set)\n",
    "                break\n",
    "\n",
    "    if tmp_cluster not in clusters:\n",
    "        clusters.append(tmp_cluster)\n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2814793/2669069357.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_sbst['id'] = df_sbst['id'].apply(lambda x: f\"{x}_c{num_camera}\")\n",
      "/tmp/ipykernel_2814793/2669069357.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_sbst['id'] = df_sbst['id'].apply(lambda x: f\"{x}_c{num_camera}\")\n",
      "/tmp/ipykernel_2814793/2669069357.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_sbst['id'] = df_sbst['id'].apply(lambda x: f\"{x}_c{num_camera}\")\n",
      "/tmp/ipykernel_2814793/2669069357.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_sbst['id'] = df_sbst['id'].apply(lambda x: f\"{x}_c{num_camera}\")\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "descriptors = []\n",
    "index2track = {}\n",
    "index = 0\n",
    "aidf1_max = 0.0\n",
    "output_dir = '/ssd/r.musaev/deepsort/outputs/58'\n",
    "\n",
    "for num_camera, camera_hyp in enumerate(sorted(glob.glob(f\"{output_dir}/*.txt\"))):\n",
    "    df = pd.read_csv(\n",
    "        camera_hyp,\n",
    "        names=[\n",
    "            'fr_num', 'id', 'bbleft', 'bbtop',\n",
    "            'bbox_width', 'bbox_height', 'det_score',\n",
    "            'class', 'visibility', 'stuff', 'desc_reid'\n",
    "        ],\n",
    "        index_col=False\n",
    "    )\n",
    "    df['camera'] = num_camera\n",
    "    df_sbst = df[['fr_num', 'id', 'bbleft', 'bbtop',\n",
    "                    'bbox_width', 'bbox_height', 'det_score', 'class']]\n",
    "    df_sbst['id'] = df_sbst['id'].apply(lambda x: f\"{x}_c{num_camera}\")\n",
    "\n",
    "    # Re-ID preparation: agg and normalize\n",
    "    df['desc_reid'] = df['desc_reid'].apply(lambda x: np.array(ast.literal_eval(x)))\n",
    "    df = df.groupby('id')['desc_reid'].agg('mean')\n",
    "\n",
    "    tracks = [f\"{x}_c{num_camera}\" for x in df.keys()]\n",
    "    tracks = dict(zip(range(index, index + len(df.keys())), tracks))\n",
    "\n",
    "    index += len(df.keys())\n",
    "    index2track.update(tracks)\n",
    "\n",
    "    descs = np.vstack(df.values.tolist())\n",
    "    descriptors.append(descs)\n",
    "\n",
    "descriptors = np.vstack(descriptors)\n",
    "dist = pairwise_distances(descriptors, metric='euclidean')\n",
    "\n",
    "# Loop for h -> clustering -> precision/recall\n",
    "precision, recall, fp_rate = [], [], []\n",
    "sample_rate = 100\n",
    "thresholds = np.linspace(dist.min(), dist.max(), sample_rate)\n",
    "\n",
    "for threshold in tqdm(thresholds):\n",
    "    track2cluster = clusterize(dist, threshold, index2track)\n",
    "    break\n",
    "    # hyp_obj_pairs_h = convert_tracks(hyp_obj_pairs, track2cluster)\n",
    "    # precision_h, recall_h, fp_rate_h = bcubed_eval(hyp_obj_pairs_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2814793/2555131439.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_sbst['id'] = df_sbst['id'].apply(lambda x: f\"{x}_c{num_camera}\")\n",
      "/tmp/ipykernel_2814793/2555131439.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_sbst['id'] = df_sbst['id'].apply(lambda x: f\"{x}_c{num_camera}\")\n",
      "/tmp/ipykernel_2814793/2555131439.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_sbst['id'] = df_sbst['id'].apply(lambda x: f\"{x}_c{num_camera}\")\n",
      "/tmp/ipykernel_2814793/2555131439.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_sbst['id'] = df_sbst['id'].apply(lambda x: f\"{x}_c{num_camera}\")\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "descriptors = []\n",
    "index2track = {}\n",
    "index = 0\n",
    "aidf1_max = 0.0\n",
    "\n",
    "df_mcmt = pd.DataFrame(\n",
    "    columns=[\n",
    "        'fr_num', 'id', 'bbleft', 'bbtop',\n",
    "        'bbox_width', 'bbox_height', 'det_score', 'class'\n",
    "    ]\n",
    ")\n",
    "\n",
    "for num_camera, camera_hyp in enumerate(sorted(glob.glob(f\"{output_dir}/*.txt\"))):\n",
    "    df = pd.read_csv(\n",
    "        camera_hyp,\n",
    "        names=[\n",
    "            'fr_num', 'id', 'bbleft', 'bbtop',\n",
    "            'bbox_width', 'bbox_height', 'det_score',\n",
    "            'class', 'visibility', 'stuff', 'desc_reid'\n",
    "        ],\n",
    "        index_col=False\n",
    "    )\n",
    "    df['camera'] = num_camera\n",
    "\n",
    "    df_sbst = df[['fr_num', 'id', 'bbleft', 'bbtop',\n",
    "                    'bbox_width', 'bbox_height', 'det_score', 'class']]\n",
    "    df_sbst['id'] = df_sbst['id'].apply(lambda x: f\"{x}_c{num_camera}\")\n",
    "\n",
    "\n",
    "    df_mcmt = pd.concat([df_mcmt, df_sbst])\n",
    "\n",
    "    # Re-ID preparation: agg and normalize\n",
    "    df['desc_reid'] = df['desc_reid'].apply(lambda x: np.array(ast.literal_eval(x)))\n",
    "    df = df.groupby('id')['desc_reid'].agg('mean')\n",
    "    df = df.apply(lambda x: normalize(x))\n",
    "\n",
    "    tracks = [f\"{x}_c{num_camera}\" for x in df.keys()]\n",
    "    tracks = dict(zip(range(index, index + len(df.keys())), tracks))\n",
    "\n",
    "    index += len(df.keys())\n",
    "    index2track.update(tracks)\n",
    "\n",
    "    descs = np.vstack(df.values.tolist())\n",
    "    descriptors.append(descs)\n",
    "\n",
    "descriptors = np.vstack(descriptors)\n",
    "dist = pairwise_distances(descriptors, metric='euclidean')\n",
    "\n",
    "# Loop for h -> clustering -> precision/recall\n",
    "precision, recall, fp_rate = [], [], []\n",
    "sample_rate = 100\n",
    "thresholds = np.linspace(dist.min(), dist.max(), sample_rate)\n",
    "import sys; sys.breakpointhook()\n",
    "\n",
    "for threshold in tqdm(thresholds):\n",
    "    track2cluster = clusterize(dist, threshold, index2track)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mcmt['id'] = df_mcmt['id'].apply(lambda x: track2cluster[x])\n",
    "df_mcmt.to_csv(os.path.join(output_dir, \"computed_mcmt.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
